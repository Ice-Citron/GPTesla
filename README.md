# GPTesla
This is my research for my CS Research Paper and hobby. I'm creating a transformer/LLM from scratch with decoder architecture. I am following O'reilly's NLP book for guidance to create this transformer, which should be a &lt;100 million parameter model, that generates Python code based on prompt simillar to GitHub co-pilot. Resource used for now is 4x Nvidia A100 80GB from Nvidia. 
