{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8490f0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Update package list and install Python 3.9\\n!sudo apt-get update\\n!sudo apt-get install -y python3.9\\n\\n# Set up update-alternatives to point to the new Python version\\n!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\\n!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\\n\\n# Select the new Python version as default\\n!sudo update-alternatives --config python3\\n\\n# Verify the Python version\\n!python3 --version\\n\\n# Upgrade pip and install necessary packages\\n!python3 -m pip install --upgrade pip\\n!python3 -m pip install jupyter\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "# run manually in terminal in the future\n",
    "\"\"\"\n",
    "# Update package list and install Python 3.9\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y python3.9\n",
    "\n",
    "# Set up update-alternatives to point to the new Python version\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
    "\n",
    "# Select the new Python version as default\n",
    "!sudo update-alternatives --config python3\n",
    "\n",
    "# Verify the Python version\n",
    "!python3 --version\n",
    "\n",
    "# Upgrade pip and install necessary packages\n",
    "!python3 -m pip install --upgrade pip\n",
    "!python3 -m pip install jupyter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf42d961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.5\n",
      "Python 3.9.5\n"
     ]
    }
   ],
   "source": [
    "# Verify the installation\n",
    "!python --version\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c710dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "%cd notebooks\n",
    "#from install import *\n",
    "#install_requirements(is_chapter6=True)\n",
    "\"\"\"\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86cf199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set TOKENIZERS_PARALLELISM to true or false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2f1a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.9/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests==2.32.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests==2.32.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests==2.32.3) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests==2.32.3) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.9/dist-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.9/dist-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.9/dist-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (1.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.18.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.18.0) (10.4.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.3.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (8.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata) (3.19.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (0.32.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: psutil==6.0.0 in /usr/local/lib/python3.9/dist-packages (6.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: matplotlib==3.9.1 in /usr/local/lib/python3.9/dist-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.9.1) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.9.1) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (3.0.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting ipython\n",
      "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting decorator (from ipython)\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jedi>=0.16 (from ipython)\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting matplotlib-inline (from ipython)\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython)\n",
      "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pygments>=2.4.0 (from ipython)\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting stack-data (from ipython)\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting traitlets>=5 (from ipython)\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions (from ipython)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting exceptiongroup (from ipython)\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pexpect>4.3 (from ipython)\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython)\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython)\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython)\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting executing>=1.2.0 (from stack-data->ipython)\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack-data->ipython)\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pure-eval (from stack-data->ipython)\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting six>=1.12.0 (from asttokens>=2.1.0->stack-data->ipython)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.2/808.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m187.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m301.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m368.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m384.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m271.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: wcwidth, pure-eval, ptyprocess, typing-extensions, traitlets, six, pygments, prompt-toolkit, pexpect, parso, executing, exceptiongroup, decorator, matplotlib-inline, jedi, asttokens, stack-data, ipython\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.13\n",
      "    Uninstalling wcwidth-0.2.13:\n",
      "      Successfully uninstalled wcwidth-0.2.13\n",
      "  Attempting uninstall: pure-eval\n",
      "    Found existing installation: pure-eval 0.2.2\n",
      "    Uninstalling pure-eval-0.2.2:\n",
      "      Successfully uninstalled pure-eval-0.2.2\n",
      "  Attempting uninstall: ptyprocess\n",
      "    Found existing installation: ptyprocess 0.7.0\n",
      "    Uninstalling ptyprocess-0.7.0:\n",
      "      Successfully uninstalled ptyprocess-0.7.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.14.3\n",
      "    Uninstalling traitlets-5.14.3:\n",
      "      Successfully uninstalled traitlets-5.14.3\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.18.0\n",
      "    Uninstalling Pygments-2.18.0:\n",
      "      Successfully uninstalled Pygments-2.18.0\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt_toolkit 3.0.47\n",
      "    Uninstalling prompt_toolkit-3.0.47:\n",
      "      Successfully uninstalled prompt_toolkit-3.0.47\n",
      "  Attempting uninstall: pexpect\n",
      "    Found existing installation: pexpect 4.9.0\n",
      "    Uninstalling pexpect-4.9.0:\n",
      "      Successfully uninstalled pexpect-4.9.0\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.4\n",
      "    Uninstalling parso-0.8.4:\n",
      "      Successfully uninstalled parso-0.8.4\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 2.0.1\n",
      "    Uninstalling executing-2.0.1:\n",
      "      Successfully uninstalled executing-2.0.1\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.2.1\n",
      "    Uninstalling exceptiongroup-1.2.1:\n",
      "      Successfully uninstalled exceptiongroup-1.2.1\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "  Attempting uninstall: matplotlib-inline\n",
      "    Found existing installation: matplotlib-inline 0.1.7\n",
      "    Uninstalling matplotlib-inline-0.1.7:\n",
      "      Successfully uninstalled matplotlib-inline-0.1.7\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.1\n",
      "    Uninstalling jedi-0.19.1:\n",
      "      Successfully uninstalled jedi-0.19.1\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 2.4.1\n",
      "    Uninstalling asttokens-2.4.1:\n",
      "      Successfully uninstalled asttokens-2.4.1\n",
      "  Attempting uninstall: stack-data\n",
      "    Found existing installation: stack-data 0.6.3\n",
      "    Uninstalling stack-data-0.6.3:\n",
      "      Successfully uninstalled stack-data-0.6.3\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.18.1\n",
      "    Uninstalling ipython-8.18.1:\n",
      "      Successfully uninstalled ipython-8.18.1\n",
      "Successfully installed asttokens-2.4.1 decorator-5.1.1 exceptiongroup-1.2.1 executing-2.0.1 ipython-8.18.1 jedi-0.19.1 matplotlib-inline-0.1.7 parso-0.8.4 pexpect-4.9.0 prompt-toolkit-3.0.47 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.18.0 six-1.16.0 stack-data-0.6.3 traitlets-5.14.3 typing-extensions-4.12.2 wcwidth-0.2.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (0.7.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (2.9.2-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 141 not upgraded.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboard==2.17.0 in /usr/local/lib/python3.9/dist-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (1.65.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard==2.17.0) (45.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.17.0) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard==2.17.0) (8.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard==2.17.0) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.17.0) (3.19.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "#\"\"\"\n",
    "!pip install transformers==4.41.2\n",
    "!pip install datasets==2.20.0\n",
    "\n",
    "!pip install pyarrow==16.0\n",
    "!pip install requests==2.32.3\n",
    "\n",
    "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0\n",
    "\n",
    "!pip install importlib-metadata\n",
    "\n",
    "!pip install accelerate -U\n",
    "\n",
    "!pip install psutil==6.0.0\n",
    "\n",
    "\n",
    "# Specific to Nvidia Instance\n",
    "!pip install matplotlib==3.9.1\n",
    "!pip install --upgrade cython\n",
    "!pip install --upgrade --force-reinstall ipython\n",
    "!pip install pickleshare\n",
    "!sudo apt-get install git-lfs\n",
    "\n",
    "# Specific to Nvidia Instance + Training GPT\n",
    "!pip install tensorboard==2.17.0\n",
    "!pip install wandb==0.17.4\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23061a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.41.2\n",
      "Using datasets v2.20.0\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ee2c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyarrow\n",
      "Version: 16.0.0\n",
      "Summary: Python library for Apache Arrow\n",
      "Home-page: https://arrow.apache.org/\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache License, Version 2.0\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: numpy\n",
      "Required-by: datasets\n",
      "---\n",
      "Name: requests\n",
      "Version: 2.32.3\n",
      "Summary: Python HTTP for Humans.\n",
      "Home-page: https://requests.readthedocs.io\n",
      "Author: Kenneth Reitz\n",
      "Author-email: me@kennethreitz.org\n",
      "License: Apache-2.0\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: certifi, charset-normalizer, idna, urllib3\n",
      "Required-by: datasets, huggingface-hub, jupyterlab_server, transformers\n",
      "---\n",
      "Name: transformers\n",
      "Version: 4.41.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "---\n",
      "Name: datasets\n",
      "Version: 2.20.0\n",
      "Summary: HuggingFace community-driven open-source library of datasets\n",
      "Home-page: https://github.com/huggingface/datasets\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyarrow-hotfix, pyyaml, requests, tqdm, xxhash\n",
      "Required-by: \n",
      "---\n",
      "Name: torch\n",
      "Version: 2.3.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, torchaudio, torchvision\n",
      "---\n",
      "Name: torchaudio\n",
      "Version: 2.3.0\n",
      "Summary: An audio package for PyTorch\n",
      "Home-page: https://github.com/pytorch/audio\n",
      "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
      "Author-email: soumith@pytorch.org\n",
      "License: \n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: torch\n",
      "Required-by: \n",
      "---\n",
      "Name: importlib_metadata\n",
      "Version: 8.0.0\n",
      "Summary: Read metadata from Python packages\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \"Jason R. Coombs\" <jaraco@jaraco.com>\n",
      "License: \n",
      "Location: /usr/local/lib/python3.9/dist-packages\n",
      "Requires: zipp\n",
      "Required-by: jupyter-lsp, jupyter_client, jupyterlab, jupyterlab_server, Markdown, nbconvert\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "# Verifying packages installed are now up to date\n",
    "!pip show pyarrow requests transformers datasets torch torchaudio importlib-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6764190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 11 10:57:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              52W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              54W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              54W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              56W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25916f9",
   "metadata": {},
   "source": [
    "# Training Transformers from Scratch (small model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84069ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API token as an environment variable\n",
    "os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d7a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"shng2025/gptesla\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "config_small = AutoConfig.from_pretrained(\"gpt2\", vocab_size=len(tokenizer))\n",
    "model_small = AutoModelForCausalLM.from_config(config_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "400705c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 111.0M parameters\n"
     ]
    }
   ],
   "source": [
    "def model_size(model):\n",
    "    return sum(t.numel() for t in model.parameters())\n",
    "\n",
    "print(f'GPT-2 size: {model_size(model_small)/1000**2:.1f}M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d31fd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a376bcec291440da8f6751f18adf4b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb5bf61053345adb2e98c8fc9f004f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/444M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_small.save_pretrained(\"models/\" + model_ckpt + \"-small\", push_to_hub=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb6185",
   "metadata": {},
   "source": [
    "### Implementing the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87d7fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class ConstantLengthDataset(IterableDataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, dataset, seq_length=1024,\n",
    "                 num_of_sequences=1024, chars_per_token=3.6):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.concat_token_id = tokenizer.eos_token_id\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.input_characters = seq_length * chars_per_token * num_of_sequences\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        more_examples = True\n",
    "        while more_examples:\n",
    "            buffer, buffer_len = [], 0\n",
    "            while True:\n",
    "                if buffer_len >= self.input_characters:\n",
    "                    m=f\"Buffer full: {buffer_len}>={self.input_characters:.0f}\"\n",
    "                    print(m)\n",
    "                    break\n",
    "                try:\n",
    "                    m=f\"Fill buffer: {buffer_len}<{self.input_characters:.0f}\"\n",
    "                    print(m)\n",
    "                    buffer.append(next(iterator)[\"content\"])\n",
    "                    buffer_len += len(buffer[-1])\n",
    "                except StopIteration:\n",
    "                    #iterator = iter(self.dataset)\n",
    "                    more_examples = False\n",
    "                    break\n",
    "\n",
    "            all_token_ids = []\n",
    "            tokenized_inputs = self.tokenizer(buffer, truncation=False)\n",
    "            for tokenized_input in tokenized_inputs['input_ids']:\n",
    "                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n",
    "            \n",
    "            for i in range(0, len(all_token_ids), self.seq_length):\n",
    "                input_ids = all_token_ids[i : i + self.seq_length]\n",
    "                if len(input_ids) == self.seq_length:\n",
    "                    yield torch.tensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af07139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a748423e57174121b6ee98f494b58c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill buffer: 0<36864\n",
      "Fill buffer: 1144<36864\n",
      "Fill buffer: 5881<36864\n",
      "Fill buffer: 17574<36864\n",
      "Buffer full: 37366>=36864\n",
      "Lengths of the sequences: [1024, 1024, 1024, 1024, 1024]\n"
     ]
    }
   ],
   "source": [
    "# Testing the Dataloader\n",
    "from datasets import load_dataset, DownloadConfig\n",
    "dataset = load_dataset('shng2025/gptesla-train', split='train', streaming=True)\n",
    "\n",
    "shuffled_dataset = dataset.shuffle(buffer_size=100)\n",
    "constant_length_dataset = ConstantLengthDataset(tokenizer, shuffled_dataset,\n",
    "                                                num_of_sequences=10)\n",
    "dataset_iterator = iter(constant_length_dataset)\n",
    "\n",
    "lengths = [len(b) for _, b in zip(range(5), dataset_iterator)]\n",
    "print(f\"Lengths of the sequences: {lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a6dad",
   "metadata": {},
   "source": [
    "### Defining the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b831f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "# GPTesla - 111M param setup in comment. Modification to make lighter training requirement needed\n",
    "config = {\"train_batch_size\": 12, # 12\n",
    "          \"valid_batch_size\": 12, # 12\n",
    "          \"weight_decay\": 0.1,\n",
    "          \"shuffle_buffer\": 1000,\n",
    "          \"learning_rate\": 5e-4, # 5e-4\n",
    "          \"lr_scheduler_type\": \"cosine\",\n",
    "          \"num_warmup_steps\": 2000, # 2000\n",
    "          \"gradient_accumulation_steps\": 1, # 1\n",
    "          \"max_train_steps\": 1000, # 150000\n",
    "          \"max_eval_steps\": -1,\n",
    "          \"seq_length\": 1024,\n",
    "          \"seed\": 1,\n",
    "          \"save_checkpoint_steps\": 1000} # 15000\n",
    "\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "272fe435",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_logging\u001b[39m(project_name):\n\u001b[1;32m      6\u001b[0m     logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "def setup_logging(project_name):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\", level=logging.INFO, handlers=[\n",
    "        logging.FileHandler(f\"log/debug_{accelerator.process_index}.log\"),\n",
    "        logging.StreamHandler()])\n",
    "    if accelerator.is_main_process: # We only want to set up logging once\n",
    "        wandb.init(project=project_name, config=args)\n",
    "        run_name = wandb.run.name\n",
    "        tb_writer = SummaryWriter()\n",
    "        tb_writer.add_hparams(vars(args), {'0': 0})\n",
    "        logger.setLevel(logging.INFO)\n",
    "        datasets.utils.logging.set_verbosity_debug()\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        tb_writer = None\n",
    "        run_name = ''\n",
    "        logger.setLevel(logging.ERROR)\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "    return logger, tb_writer, run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(step, metrics):\n",
    "    logger.info(f\"Step {step}: {metrics}\")\n",
    "    if accelerator.is_main_process:\n",
    "        wandb.log(metrics)\n",
    "        [tb_writer.add_scalar(k, v, step) for k, v in metrics.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "def create_dataloaders(dataset_name):\n",
    "    train_data = load_dataset(dataset_name+'-train', split=\"train\",\n",
    "                              streaming=True)\n",
    "    train_data = train_data.shuffle(buffer_size=args.shuffle_buffer,\n",
    "                                    seed=args.seed)\n",
    "    valid_data = load_dataset(dataset_name+'-valid', split=\"validation\",\n",
    "                              streaming=True)\n",
    "    \n",
    "    train_dataset = ConstantLengthDataset(tokenizer, train_data,\n",
    "                                          seq_length=args.seq_length)\n",
    "    valid_dataset = ConstantLengthDataset(tokenizer, valid_data,\n",
    "                                          seq_length=args.seq_length)\n",
    "    \n",
    "    train_dataloader=DataLoader(train_dataset, batch_size=args.train_batch_size)\n",
    "    eval_dataloader=DataLoader(valid_dataset, batch_size=args.valid_batch_size)\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [{'params': params_with_wd, 'weight_decay': args.weight_decay},\n",
    "            {'params': params_without_wd, 'weight_decay': 0.0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ef16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss.repeat(args.valid_batch_size)\n",
    "        losses.append(accelerator.gather(loss))\n",
    "        if args.max_eval_steps > 0 and step >= args.max_eval_steps: break\n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "\t\tperplexity = torch.exp(loss)\n",
    "\texcept OverflowError:\n",
    "\t\tperplexity = torch.tensor(float(\"inf\"))\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88043c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(args.seed)\n",
    "\n",
    "# Accelerator\n",
    "accelerator = Accelerator()\n",
    "samples_per_step = accelerator.state.num_processes * args.train_batch_size\n",
    "\n",
    "# Logging\n",
    "logger, tb_writer, run_name = setup_logging(project_name.split(\"/\")[1])\n",
    "logger.info(accelerator.state)\n",
    "\n",
    "# Load model and tokenizer\n",
    "if accelerator.is_main_process:\n",
    "    hf_repo = Repository(\"./\", clone_from=project_name, revision=run_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./\", gradient_checkpointing=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./\")\n",
    "\n",
    "# Load dataset and dataloader\n",
    "train_dataloader, eval_dataloader = create_dataloaders(dataset_name)\n",
    "\n",
    "# Prepare the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(get_grouped_params(model), lr=args.learning_rate)\n",
    "lr_scheduler = get_scheduler(name=args.lr_scheduler_type, optimizer=optimizer,\n",
    "                             num_warmup_steps=args.num_warmup_steps,\n",
    "                             num_training_steps=args.max_train_steps,)\n",
    "def get_lr():\n",
    "    return optimizer.param_groups[0]['lr']\n",
    "\n",
    "# Prepare everything with our `accelerator` (order of args is not important)\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader)\n",
    "\n",
    "# Train model\n",
    "model.train()\n",
    "completed_steps = 0\n",
    "for step, batch in enumerate(train_dataloader, start=1):\n",
    "    loss = model(batch, labels=batch).loss\n",
    "    log_metrics(step, {'lr': get_lr(), 'samples': step*samples_per_step,\n",
    "                       'steps': completed_steps, 'loss/train': loss.item()})\n",
    "    loss = loss / args.gradient_accumulation_steps\n",
    "    accelerator.backward(loss)\n",
    "    if step % args.gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        completed_steps += 1\n",
    "    if step % args.save_checkpoint_steps == 0:\n",
    "        logger.info('Evaluating and saving model checkpoint')\n",
    "        eval_loss, perplexity = evaluate()\n",
    "        log_metrics(step, {'loss/eval': eval_loss, 'perplexity': perplexity})\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        if accelerator.is_main_process:\n",
    "            unwrapped_model.save_pretrained(\"./\")\n",
    "            hf_repo.push_to_hub(commit_message=f'step {step}')\n",
    "        model.train()\n",
    "    if completed_steps >= args.max_train_steps:\n",
    "        break\n",
    "\n",
    "# Evaluate and save the last checkpoint\n",
    "logger.info('Evaluating and saving model after training')\n",
    "eval_loss, perplexity = evaluate()\n",
    "log_metrics(step, {'loss/eval': eval_loss, 'perplexity': perplexity})\n",
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "if accelerator.is_main_process:\n",
    "    unwrapped_model.save_pretrained(\"./\")\n",
    "    hf_repo.push_to_hub(commit_message=f'final model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad0ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f381b17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Don't forget to intialise variables etc from tokenizer_training.ipynb // check library compatibility etc.\n",
    "\n",
    "#       -- useful terminal code // for cpu monitoring: \"top\" // if gpu \"watch -n 1 nvidia-smi\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
