{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b5bc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Update package list and install Python 3.9\\n!sudo apt-get update\\n!sudo apt-get install -y python3.9\\n\\n# Set up update-alternatives to point to the new Python version\\n!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\\n!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\\n\\n# Select the new Python version as default\\n!sudo update-alternatives --config python3\\n\\n# Verify the Python version\\n!python3 --version\\n\\n# Upgrade pip and install necessary packages\\n!python3 -m pip install --upgrade pip\\n!python3 -m pip install jupyter\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "# run manually in terminal in the future\n",
    "\"\"\"\n",
    "# Update package list and install Python 3.9\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y python3.9\n",
    "\n",
    "# Set up update-alternatives to point to the new Python version\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
    "\n",
    "# Select the new Python version as default\n",
    "!sudo update-alternatives --config python3\n",
    "\n",
    "# Verify the Python version\n",
    "!python3 --version\n",
    "\n",
    "# Upgrade pip and install necessary packages\n",
    "!python3 -m pip install --upgrade pip\n",
    "!python3 -m pip install jupyter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9063b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.5\n",
      "Python 3.9.5\n"
     ]
    }
   ],
   "source": [
    "# Verify the installation\n",
    "!python --version\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0627d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "%cd notebooks\n",
    "#from install import *\n",
    "#install_requirements(is_chapter6=True)\n",
    "\"\"\"\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#\"\"\"\n",
    "!pip install transformers==4.41.2\n",
    "!pip install datasets==2.20.0\n",
    "\n",
    "!pip install pyarrow==16.0\n",
    "!pip install requests==2.32.3\n",
    "\n",
    "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0\n",
    "\n",
    "!pip install importlib-metadata\n",
    "\n",
    "!pip install accelerate -U\n",
    "\n",
    "!pip install psutil==6.0.0\n",
    "\n",
    "\n",
    "# Specific to Nvidia Instance\n",
    "!pip install matplotlib==3.9.1\n",
    "!pip install --upgrade cython\n",
    "!pip install --upgrade --force-reinstall ipython\n",
    "!pip install pickleshare\n",
    "!sudo apt-get install git-lfs\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96330c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.41.2\n",
      "Using datasets v2.20.0\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "# Verifying packages installed are now up to date\n",
    "!pip show pyarrow requests transformers datasets torch torchaudio importlib-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5819e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  9 14:04:47 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              53W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              55W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              53W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              57W / 300W |      7MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3018122",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a8216",
   "metadata": {},
   "source": [
    "# Training Transformers from Scratch (small model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9edb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API token as an environment variable\n",
    "os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "181d34c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d28839dce3435486cbc65dae7c4787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074500d6855e4c1989abe5f45f85a9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/496k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c392dd3c0a794067a6447e710f0e5044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/276k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69c6b5ea5de4af2a9298979a155b2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e2da7039834766b8c354b2e11219aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0939f3c06cb4ba3ae85507994bd4038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"shng2025/gptesla\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "config_small = AutoConfig.from_pretrained(\"gpt2\", vocab_size=len(tokenizer))\n",
    "model_small = AutoModelForCausalLM.from_config(config_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6435d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 111.0M parameters\n"
     ]
    }
   ],
   "source": [
    "def model_size(model):\n",
    "    return sum(t.numel() for t in model.parameters())\n",
    "\n",
    "print(f'GPT-2 size: {model_size(model_small)/1000**2:.1f}M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427cf578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6752d080c7445ec87dc197d99ca72e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/444M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_small.save_pretrained(\"models/\" + model_ckpt + \"-small\", push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98633c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0563c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12187a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Don't forget to intialise variables etc from tokenizer_training.ipynb // check library compatibility etc.\n",
    "\n",
    "#       -- useful terminal code // for cpu monitoring: \"top\" // if gpu \"watch -n 1 nvidia-smi\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
